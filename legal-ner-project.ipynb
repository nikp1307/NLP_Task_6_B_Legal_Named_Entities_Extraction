{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import json\n \nwith open('/kaggle/input/legalner-dataset/NER_TRAIN_PREAMBLE.json','r') as f:\n    data = json.load(f)","metadata":{"execution":{"iopub.status.busy":"2022-12-10T18:45:34.091020Z","iopub.execute_input":"2022-12-10T18:45:34.091466Z","iopub.status.idle":"2022-12-10T18:45:34.186633Z","shell.execute_reply.started":"2022-12-10T18:45:34.091407Z","shell.execute_reply":"2022-12-10T18:45:34.185592Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"training_data = {'classes' : [], 'annotations' : []}\nfor example in data:\n  \n  if len(example['annotations']) >= 1 and len(example['annotations'][0]['result']) >= 1:\n    temp_dict = {}\n    temp_dict['text'] = example['data']['text']\n    temp_dict['entities'] = []\n    start = example['annotations'][0]['result'][0]['value']['start']\n    end = example['annotations'][0]['result'][0]['value']['end']\n    label = example['annotations'][0]['result'][0]['value']['labels'][0].upper()\n    temp_dict['entities'].append((start, end, label))\n    training_data['annotations'].append(temp_dict)\nprint(training_data['annotations'][0])\n#     for train_data in example['annotations'][0]['result']:\n#         start = train_data['value']['start']\n#         end = train_data['value']['end']\n#         label = train_data['value']['labels'][0].upper()\n#         temp_dict['entities'].append((start, end, label))\n#         training_data['annotations'].append(temp_dict)\n        \n","metadata":{"execution":{"iopub.status.busy":"2022-12-10T18:46:00.884856Z","iopub.execute_input":"2022-12-10T18:46:00.885239Z","iopub.status.idle":"2022-12-10T18:46:00.906951Z","shell.execute_reply.started":"2022-12-10T18:46:00.885205Z","shell.execute_reply":"2022-12-10T18:46:00.904765Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"{'text': \"In The High Court Of Kerala At Ernakulam\\n\\nCrl Mc No. 1622 of 2006()\\n\\n\\n1. T.R.Ajayan, S/O. O.Raman,\\n                      ...  Petitioner\\n\\n                        Vs\\n\\n\\n\\n1. M.Ravindran,\\n                       ...       Respondent\\n\\n2. Mrs. Nirmala Dinesh, W/O. Dinesh,\\n\\n                For Petitioner  :Sri.A.Kumar\\n\\n                For Respondent  :Smt.M.K.Pushpalatha\\n\\nThe Hon'ble Mr. Justice P.R.Raman\\nThe Hon'ble Mr. Justice V.K.Mohanan\\n\\n Dated :07/01/2008\\n\\n O R D E R\\n\", 'entities': [(7, 40, 'COURT')]}\n","output_type":"stream"}]},{"cell_type":"code","source":"import spacy\nfrom spacy.tokens import DocBin\nfrom tqdm import tqdm\n\nnlp = spacy.blank(\"en\") # load a new spacy model\ndoc_bin = DocBin() # create a DocBin object","metadata":{"execution":{"iopub.status.busy":"2022-12-10T18:46:08.787897Z","iopub.execute_input":"2022-12-10T18:46:08.788317Z","iopub.status.idle":"2022-12-10T18:46:08.949734Z","shell.execute_reply.started":"2022-12-10T18:46:08.788279Z","shell.execute_reply":"2022-12-10T18:46:08.948683Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"from spacy.util import filter_spans\n\nfor training_example  in tqdm(training_data['annotations']): \n    text = training_example['text']\n    labels = training_example['entities']\n    doc = nlp.make_doc(text) \n    ents = []\n    for start, end, label in labels:\n        span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n        if span is None:\n            print(\"Skipping entity\")\n        else:\n            ents.append(span)\n    filtered_ents = filter_spans(ents)\n    doc.ents = filtered_ents \n    doc_bin.add(doc)\n\ndoc_bin.to_disk(\"trn_data.spacy\") # save the docbin object","metadata":{"execution":{"iopub.status.busy":"2022-12-10T18:46:12.148391Z","iopub.execute_input":"2022-12-10T18:46:12.149128Z","iopub.status.idle":"2022-12-10T18:46:16.035690Z","shell.execute_reply.started":"2022-12-10T18:46:12.149090Z","shell.execute_reply":"2022-12-10T18:46:16.034671Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stderr","text":"100%|██████████| 1558/1558 [00:03<00:00, 464.13it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"!python -m spacy init fill-config /kaggle/input/configfiles/base_config.cfg config.cfg","metadata":{"execution":{"iopub.status.busy":"2022-12-10T18:46:48.867108Z","iopub.execute_input":"2022-12-10T18:46:48.867723Z","iopub.status.idle":"2022-12-10T18:46:55.961047Z","shell.execute_reply.started":"2022-12-10T18:46:48.867679Z","shell.execute_reply":"2022-12-10T18:46:55.959754Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n\u001b[38;5;2m✔ Saved config\u001b[0m\nconfig.cfg\nYou can now add your data and train your pipeline:\npython -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n","output_type":"stream"}]},{"cell_type":"code","source":"!python -m spacy train config.cfg --output ./ --paths.train ./trn_data.spacy --paths.dev ./trn_data.spacy --gpu-id 0","metadata":{"execution":{"iopub.status.busy":"2022-12-10T18:47:55.398874Z","iopub.execute_input":"2022-12-10T18:47:55.399972Z","iopub.status.idle":"2022-12-10T18:57:56.855370Z","shell.execute_reply.started":"2022-12-10T18:47:55.399927Z","shell.execute_reply":"2022-12-10T18:57:56.854148Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"\u001b[38;5;4mℹ Saving to output directory: .\u001b[0m\n\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n\u001b[1m\n=========================== Initializing pipeline ===========================\u001b[0m\n[2022-12-10 18:48:05,644] [INFO] Set up nlp object from config\n[2022-12-10 18:48:05,655] [INFO] Pipeline: ['transformer', 'ner']\n[2022-12-10 18:48:05,660] [INFO] Created vocabulary\n[2022-12-10 18:48:05,661] [INFO] Finished initializing nlp object\nDownloading: 100%|██████████████████████████████| 480/480 [00:00<00:00, 393kB/s]\nDownloading: 100%|████████████████████████████| 878k/878k [00:01<00:00, 898kB/s]\nDownloading: 100%|████████████████████████████| 446k/446k [00:00<00:00, 461kB/s]\nDownloading: 100%|█████████████████████████| 1.29M/1.29M [00:01<00:00, 1.13MB/s]\nDownloading: 100%|███████████████████████████| 316M/316M [00:21<00:00, 15.5MB/s]\nSome weights of the model checkpoint at distilroberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n[2022-12-10 18:48:56,799] [INFO] Initialized pipeline components: ['transformer', 'ner']\n\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n\u001b[1m\n============================= Training pipeline =============================\u001b[0m\n\u001b[38;5;4mℹ Pipeline: ['transformer', 'ner']\u001b[0m\n\u001b[38;5;4mℹ Initial learn rate: 0.0\u001b[0m\nE    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n---  ------  -------------  --------  ------  ------  ------  ------\nToken indices sequence length is longer than the specified maximum sequence length for this model (993 > 512). Running this sequence through the model will result in indexing errors\n  0       0        5439.77    753.75    0.32    0.16    6.87    0.00\n  1     200      252701.92  78640.43   44.76   41.26   48.91    0.45\n  2     400        1658.68  61433.98   62.66   61.44   63.93    0.63\n^C\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}